{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba0cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking.analysis.analyze_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef44dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impls = [\"threaded\", \"asyncio\", \"vanilla\"]\n",
    "impls = [\"threaded\", \"asyncio\"]\n",
    "libs = [\"torch\", \"lightning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c0b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(\n",
    "    output_base_folder: Path, folder_filter: str = \"**\", filter_by_metadata: Dict[str, List[str]] = None,\n",
    "):\n",
    "    files = list(output_base_folder.rglob(f\"{folder_filter}/results-*.log\"))\n",
    "    data = []\n",
    "    for working_file_path in tqdm.tqdm(files, total=len(files)):\n",
    "        results = parse_results_log(working_file_path)\n",
    "        if len(results) == 0:\n",
    "            continue\n",
    "        with (working_file_path.parent / \"metadata.json\").open(\"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "        if filter_by_metadata is not None:\n",
    "            for k, v in filter_by_metadata.items():\n",
    "                if metadata[k] not in v:\n",
    "                    continue\n",
    "        results = pd.DataFrame.from_records(data=results)\n",
    "\n",
    "        for k, v in metadata.items():\n",
    "            if not isinstance(v, (int, float, complex)):\n",
    "                results[k] = str(v)\n",
    "            else:\n",
    "                results[k] = v\n",
    "\n",
    "        results[\"source_file\"] = working_file_path\n",
    "        results[\"run\"] = working_file_path.parent.name\n",
    "\n",
    "        # filter out old data format missing dataset etc.\n",
    "        if \"dataset\" not in results.columns:\n",
    "            continue\n",
    "\n",
    "        data.append(results)\n",
    "    df = pd.concat(data)\n",
    "    df.groupby\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f9c871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_returns_data(folder_filter=\"*e2e*\"):\n",
    "    output_base_folder = Path(\"/iarai/home/moritz.neun/git/storage-benchmarking/benchmark_output/\")\n",
    "    df_dataloader_s3 = extract_timelines(output_base_folder, folder_filter=folder_filter)\n",
    "    \n",
    "    df_details_s3 = extract_metadata(output_base_folder, folder_filter=folder_filter)\n",
    "    \n",
    "    # extract unique functions (for s3 and scratch, it's the same)\n",
    "    unique_functions_s3 = np.unique(df_dataloader_s3[\"item_x\"])\n",
    "\n",
    "    # define colors for timelane items \n",
    "    colors = {}\n",
    "    for i, color in zip(unique_functions_s3, [\"red\", \"gold\", \"blue\", \"magenta\", \"aqua\"]):\n",
    "        colors[str(i)] = color\n",
    "    \n",
    "    # define lanes (each lane is for a single function call (i.e. usage))\n",
    "    lanes={}\n",
    "    for i, lane in zip(unique_functions_s3, range(len(unique_functions_s3))):\n",
    "        lanes[str(i)] = lane\n",
    "\n",
    "    # print to verify\n",
    "    print(f\"Unique functions: {unique_functions_s3}\")\n",
    "    print(f\"Lanes: {lanes}\")\n",
    "    \n",
    "    # get the names of the runs for the iterators later on \n",
    "    unique_runs_s3 = np.unique(df_dataloader_s3[\"run\"])\n",
    "    print(f\"Runs: {unique_runs_s3}\")\n",
    "\n",
    "    df_gpuutil_s3 = extract_gpuutil(output_base_folder, folder_filter=folder_filter)\n",
    "    \n",
    "    returns_s3 = []\n",
    "    for run in sorted(unique_runs_s3):\n",
    "        df = df_dataloader_s3[df_dataloader_s3[\"run\"]==run]\n",
    "        dfgpu = df_gpuutil_s3[df_gpuutil_s3[\"run\"]==run]\n",
    "        r = show_timelines_with_gpu(df, dfgpu, lanes, colors, run, False, True, False, 2)\n",
    "        r[\"dataset_limit\"] = df_details_s3[df_details_s3[\"run\"]==run].get(\"dataset_limit\").iloc[0]\n",
    "        r[\"epochs\"] = df_details_s3[df_details_s3[\"run\"]==run].get(\"epochs\").iloc[0]\n",
    "        returns_s3.append(r)\n",
    "    return returns_s3\n",
    "\n",
    "def plot_img_per_s(returns_data):\n",
    "    results = pd.DataFrame.from_records(data=returns_data)\n",
    "    results[\"throughput\"] = results[\"dataset_limit\"] / (results[\"runtime\"] / results[\"epochs\"])\n",
    "    results.sort_values([\"runtime\", \"library\"], ascending=True).round(2)\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    labels = []\n",
    "    for epochs in np.unique(results[\"epochs\"]):\n",
    "        data = results[(results[\"epochs\"]==epochs) & (results[\"implementation\"] != \"vanilla\")]\n",
    "        y = list(data[\"throughput\"])\n",
    "        x = range(len(y))\n",
    "        points = list(zip(data[\"implementation\"], data[\"library\"]))\n",
    "        print(points)\n",
    "        ax.plot(x, y, label=f\"epochs: {epochs}\", marker='o', linewidth=2, markersize=12)\n",
    "        for i, txt in enumerate(points):\n",
    "            print(txt)\n",
    "            ax.annotate(txt, (x[i], y[i]))\n",
    "    ax.set_xlabel(\"Experiment index\", loc=\"center\")\n",
    "    ax.set_ylabel(\"Throughput (img/s)\", loc=\"center\")\n",
    "    ax.set_ylim(0.0, 400.0)\n",
    "    ax.grid(linestyle=\"--\", which=\"both\")\n",
    "    ax.set_title(\"S3 access, different number of epochs\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b9ebc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1064/1064 [00:04<00:00, 248.67it/s]\n",
      "  4%|█████████                                                                                                                                                                                                                                 | 41/1064 [00:03<01:17, 13.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m returns_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_returns_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*e2e*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mget_returns_data\u001b[0;34m(folder_filter)\u001b[0m\n\u001b[1;32m      2\u001b[0m output_base_folder \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/iarai/home/moritz.neun/git/storage-benchmarking/benchmark_output/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_dataloader_s3 \u001b[38;5;241m=\u001b[39m extract_timelines(output_base_folder, folder_filter\u001b[38;5;241m=\u001b[39mfolder_filter)\n\u001b[0;32m----> 5\u001b[0m df_details_s3 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_base_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# extract unique functions (for s3 and scratch, it's the same)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m unique_functions_s3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(df_dataloader_s3[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_x\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mextract_metadata\u001b[0;34m(output_base_folder, folder_filter, filter_by_metadata)\u001b[0m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m working_file_path \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(files, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(files)):\n\u001b[0;32m----> 7\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mparse_results_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworking_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/git/storage-benchmarking/src/benchmarking/analysis/analyze_results.py:467\u001b[0m, in \u001b[0;36mparse_results_log\u001b[0;34m(working_file_path)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[1;32m    469\u001b[0m         skipped_lines_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/storage-benchmarking/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.conda/envs/storage-benchmarking/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/.conda/envs/storage-benchmarking/lib/python3.9/json/decoder.py:356\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "returns_data = get_returns_data(\"e2e_calibration/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4337f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_per_s(returns_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_data_120 = get_returns_data(\"e2e_calibration_120/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cfc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f12662",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_per_s(returns_data_120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
